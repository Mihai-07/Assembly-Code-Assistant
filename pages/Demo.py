from langchain_openai import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.embeddings import SentenceTransformerEmbeddings
from langchain.prompts import PromptTemplate
from langchain.callbacks.base import BaseCallbackHandler
import os
import streamlit as st

class StreamHandler(BaseCallbackHandler):
    def __init__(self, container):
        self.container = container
        self.text = ""

    def on_llm_new_token(self, token: str, **kwargs):
        self.text += token
        self.container.markdown(self.text + "▌ ")
    
container = st.empty()
handler = StreamHandler(container=container)

os.environ["DEEPSEEK_API_KEY"] = st.secrets["api_keys"]["deepseek"]

format_docs = lambda docs: "\n\n".join(doc.page_content for doc in docs)

def call_model(question: str):
    llm = ChatOpenAI(
        model="deepseek/deepseek-chat-v3-0324:free",
        temperature=0,
        streaming=True,
        callbacks=[handler],
        base_url="https://openrouter.ai/api/v1",
        api_key=os.getenv("DEEPSEEK_API_KEY")
    )

    template = """
    Answer the following question, given the context below:

    Context: {context}
    Question: {question}
    """

    prompt = PromptTemplate(
        input_variables=["context", "question"],
        template=template
    )

    chain = prompt | llm

    store = FAISS.load_local(
        folder_path="x86-asm-docs",
        embeddings=SentenceTransformerEmbeddings(),
        allow_dangerous_deserialization=True,
    )

    retriever = store.as_retriever(search_kwargs={"k": 3})

    context = format_docs(
        retriever.invoke(question)
    )

    return chain.invoke({
        "context": context,
        "question": question
    }).content

question = st.text_input(" ", placeholder="Ask me anything")
button = st.button("▶️ Send")

if button:
    if not question:
        st.error("❌ Please type something here!")
    else:
        try:
            with st.spinner("⬇️ Retrieving information and generating response..."):
                result = call_model(question=question)
            st.warning("⚠️ This response is generated by AI and may contain inaccuracies. Use at your own risk.")
        except Exception as e:
            st.error("❌️ An error has occured! Please try again later.")
            print(e)
